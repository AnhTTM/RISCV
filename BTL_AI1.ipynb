{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnhTTM/RISCV/blob/main/BTL_AI1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXnilzv0AEjr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "#from scipy.misc import imread\n",
        "from imageio import imread\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOCaHEb7H6_5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTMHkZ8UISEa"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/Colab_Notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qpKdYiXgpBh"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMAc4K4CIW6Z"
      },
      "outputs": [],
      "source": [
        "#!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93EzzIPhIn4S"
      },
      "outputs": [],
      "source": [
        "#!unzip GTSRB_Final_Training_Images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOPjGUwmAGqg"
      },
      "outputs": [],
      "source": [
        "def load_data(input_size = (64,64), data_path =  '/GTSRB/Final_Training/Images'):\n",
        "    pixels = []\n",
        "    labels = []\n",
        "    # Loop qua các thư mục trong thư mục Images\n",
        "    for dir in os.listdir(data_path):\n",
        "        if dir == '.DS_Store':\n",
        "            continue\n",
        "\n",
        "        # Đọc file csv để lấy thông tin về ảnh\n",
        "        class_dir = os.path.join(data_path, dir)\n",
        "        info_file = pd.read_csv(os.path.join(class_dir, \"GT-\" + dir + '.csv'), sep=';')\n",
        "\n",
        "        # Lăp trong file\n",
        "        for row in info_file.iterrows():\n",
        "            # Đọc ảnh\n",
        "            pixel = imread(os.path.join(class_dir, row[1].Filename))\n",
        "            # Trích phần ROI theo thông tin trong file csv\n",
        "            pixel = pixel[row[1]['Roi.X1']:row[1]['Roi.X2'], row[1]['Roi.Y1']:row[1]['Roi.Y2'], :]\n",
        "            # Resize về kích cỡ chuẩn\n",
        "            img = cv2.resize(pixel, input_size)\n",
        "\n",
        "            # Thêm vào list dữ liệu\n",
        "            pixels.append(img)\n",
        "\n",
        "            # Thêm nhãn cho ảnh\n",
        "            labels.append(row[1].ClassId)\n",
        "\n",
        "    return pixels, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5tM55iEAKvn"
      },
      "outputs": [],
      "source": [
        "# Đường dẫn ảnh\n",
        "data_path = '/GTSRB/Final_Training/Images'\n",
        "pixels, labels = load_data(data_path=data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94LhIG_nAN2y"
      },
      "outputs": [],
      "source": [
        "def split_train_val_test_data(pixels, labels):\n",
        "    # Chuẩn hoá dữ liệu pixels và labels\n",
        "    pixels = np.array(pixels)\n",
        "    labels = keras.utils.np_utils.to_categorical(labels)\n",
        "\n",
        "    # Nhào trộn dữ liệu ngẫu nhiên\n",
        "    randomize = np.arange(len(pixels))\n",
        "    np.random.shuffle(randomize)\n",
        "    X = pixels[randomize]\n",
        "    print(\"X=\", X.shape)\n",
        "    y = labels[randomize]\n",
        "\n",
        "    # Chia dữ liệu theo tỷ lệ 60% train và 40% còn lại cho val và test\n",
        "    train_size = int(X.shape[0] * 0.6)\n",
        "    X_train, X_val = X[:train_size], X[train_size:]\n",
        "    y_train, y_val = y[:train_size], y[train_size:]\n",
        "\n",
        "    val_size = int(X_val.shape[0] * 0.5) # 50% của phần 40% bên trên\n",
        "    X_val, X_test = X_val[:val_size], X_val[val_size:]\n",
        "    y_val, y_test = y_val[:val_size], y_val[val_size:]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_train_val_test_data(pixels, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zGne0wQ395E"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape=(64,64,3), filter_size = (3,3), pool_size = (2, 2), output_size = 43):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, filter_size, activation='relu', input_shape=input_shape, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(16, filter_size, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=pool_size),\n",
        "        Dropout(0.2),\n",
        "        Conv2D(32, filter_size, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, filter_size, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=pool_size),\n",
        "        Dropout(0.2),\n",
        "        Conv2D(64, filter_size, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, filter_size, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=pool_size),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(2048, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(output_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY-iM-8DASjZ"
      },
      "outputs": [],
      "source": [
        "# Build model với kích thước đầu vào 64x64 và output là 43 classes\n",
        "model = build_model(input_shape=(64,64,3), output_size=43)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r22MZYGKAVVC"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                               validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54ZtS0TqNJ7c"
      },
      "outputs": [],
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dh4wCJBNRud"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x18je9EAcAx"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra model với dữ liệu mới\n",
        "print(model.evaluate(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f_bKnOcAXlp"
      },
      "outputs": [],
      "source": [
        "model.save(\"traffic_sign_model.h5\")\n",
        "#model = keras.models.load_model(\"traffic_sign_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS9nhK0L9odJ"
      },
      "outputs": [],
      "source": [
        "test = np.array([X_test[0]])\n",
        "predict = model.predict(test)\n",
        "print(predict)\n",
        "plt.imshow(X_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE1yZgH1gQn-"
      },
      "outputs": [],
      "source": [
        "Signboard=[]\n",
        "with open('Bienbao.txt') as file:\n",
        "    for line in file:\n",
        "        Signboard.append(line)\n",
        "def predict(X):\n",
        "  predict = model.predict(X)\n",
        "  index = np.argmax(predict, axis=1)\n",
        "  return index\n",
        "print(predict(test)[0], Signboard[predict(test)[0]])\n",
        "\n",
        "plt.imshow(X_test[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}